import{_ as n,o as a,c as e,ag as l}from"./chunks/framework.DEqXEGcv.js";const m=JSON.parse('{"title":"ArXiv Agent Memory 论文速览 - 2026-02-08","description":"","frontmatter":{},"headers":[],"relativePath":"20260208_agent_memory.md","filePath":"20260208_agent_memory.md","lastUpdated":null}'),i={name:"20260208_agent_memory.md"};function p(r,s,t,o,c,u){return a(),e("div",null,[...s[0]||(s[0]=[l(`<h1 id="arxiv-agent-memory-论文速览-2026-02-08" tabindex="-1">ArXiv Agent Memory 论文速览 - 2026-02-08 <a class="header-anchor" href="#arxiv-agent-memory-论文速览-2026-02-08" aria-label="Permalink to &quot;ArXiv Agent Memory 论文速览 - 2026-02-08&quot;">​</a></h1><h2 id="论文列表" tabindex="-1">论文列表 <a class="header-anchor" href="#论文列表" aria-label="Permalink to &quot;论文列表&quot;">​</a></h2><div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[1] Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</span></span>
<span class="line"><span>作者：Haozhen Zhang et al. | 单位：信息未明确</span></span>
<span class="line"><span>链接：https://arxiv.org/abs/2602.06025</span></span>
<span class="line"><span></span></span>
<span class="line"><span>简单介绍：针对 LLM agent 运行时记忆处理问题，提出 BudgetMem 框架，通过查询感知的预算层级路由实现显式性能-成本控制，包含低/中/高三级预算模块。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>详细总结</summary><p><strong>相关工作</strong>：</p><ul><li>离线记忆构建 vs 运行时记忆利用</li><li>现有方法缺乏显式性能-成本控制</li></ul><p><strong>创新点</strong>：</p><ol><li>BudgetMem 框架：结构化记忆处理为三预算层级模块</li><li>轻量级路由策略：基于 RL 训练的神经网络策略</li><li>三种层级策略：实现、推理、容量</li></ol><p><strong>效果</strong>：</p><ul><li>在 LoCoMo、LongMemEval 和 HotpotQA 上测试</li><li>高预算时超越强基线</li><li>紧预算下更好准确率-成本前沿</li></ul></details> --- <div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[2] Shared LoRA Subspaces for almost Strict Continual Learning</span></span>
<span class="line"><span>作者：Prakhar Kaushik et al. | 单位：Johns Hopkins University</span></span>
<span class="line"><span>链接：https://arxiv.org/abs/2602.06043</span></span>
<span class="line"><span></span></span>
<span class="line"><span>简单介绍：提出 Share 方法，通过学习单一共享低秩子空间实现高效持续微调，实现 100 倍参数缩减和 281 倍内存节省。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>详细总结</summary><p><strong>相关工作</strong>：</p><ul><li>传统 LoRA 缺乏严格持续学习机制</li><li>数据回放/多适配器扩展性差</li></ul><p><strong>创新点</strong>：</p><ol><li>共享低秩子空间：动态更新机制</li><li>正向知识迁移：最小化灾难性干扰</li><li>统一模型替代多适配器</li></ol><p><strong>效果</strong>：</p><ul><li>100 倍参数缩减，281 倍内存节省</li><li>性能与联合训练相当</li><li>跨图像分类、NLP、3D 姿态估计验证</li></ul></details> --- <div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[3] DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning</span></span>
<span class="line"><span>作者：Yuxing Lu et al. | 单位：Southeast University</span></span>
<span class="line"><span>链接：https://arxiv.org/abs/2602.06039</span></span>
<span class="line"><span></span></span>
<span class="line"><span>简单介绍：提出 DyTopo 框架，通过语义匹配动态重建稀疏有向通信图，实现随迭代问题求解阶段自适应调整的通信拓扑。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>详细总结</summary><p><strong>相关工作</strong>：</p><ul><li>固定通信模式难以匹配阶段依赖需求</li></ul><p><strong>创新点</strong>：</p><ol><li>动态通信图重建</li><li>语义匹配路由</li><li>可解释协调追踪</li></ol><p><strong>效果</strong>：</p><ul><li>代码生成和数学推理基准测试</li><li>平均超越最强基线 +6.2%</li></ul></details> --- <div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[4] V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval</span></span>
<span class="line"><span>作者：Dongyang Chen et al. | 单位：信息未明确</span></span>
<span class="line"><span>链接：https://arxiv.org/abs/2602.06034</span></span>
<span class="line"><span></span></span>
<span class="line"><span>简单介绍：提出 V-Retrver 框架，将多模态检索重构为基于视觉检查的 agentic 推理过程，实现假设生成与目标视觉验证的交替。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>详细总结</summary><p><strong>相关工作</strong>：</p><ul><li>现有方法依赖静态视觉编码</li><li>缺乏主动验证视觉证据能力</li></ul><p><strong>创新点</strong>：</p><ol><li>Agentic 推理框架</li><li>多模态交错推理</li><li>课程学习策略</li></ol><p><strong>效果</strong>：</p><ul><li>平均提升 23.0% 检索准确率</li><li>感知驱动推理可靠性提升</li></ul></details> --- <div class="language- vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[5] PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</span></span>
<span class="line"><span>作者：Kavana Venkatesh et al. | 单位：University of Virginia</span></span>
<span class="line"><span>链接：https://arxiv.org/abs/2602.06030</span></span>
<span class="line"><span></span></span>
<span class="line"><span>简单介绍：提出 PhysicsAgentABM，通过行为一致性智能体簇进行推理，结合符号先验、神经动态模型和认知融合，实现可扩展且校准的仿真。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><details><summary>详细总结</summary><p><strong>相关工作</strong>：</p><ul><li>LLM 多智能体系统扩展昂贵</li><li>经典 ABM 难以整合个体信号</li></ul><p><strong>创新点</strong>：</p><ol><li>三层推理架构</li><li>ANCHOR 聚类策略：减少 6-8 倍 LLM 调用</li><li>群体级推理解耦</li></ol><p><strong>效果</strong>：</p><ul><li>公共卫生、金融、社会科学验证</li><li>事件时间准确性和校准优于基线</li></ul></details> --- <p><em>搜索时间：2026-02-08 | 数据来源：ArXiv API</em></p>`,18)])])}const g=n(i,[["render",p]]);export{m as __pageData,g as default};
